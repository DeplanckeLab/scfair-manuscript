{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Step 1: Load and reshape mapping table\n",
    "mapping_wide = pd.read_csv(\"sm_cluster.mapping_table.tsv\", sep=\"\\t\", index_col=0)\n",
    "mapping_long = mapping_wide.reset_index().melt(id_vars='index', \n",
    "                                               var_name='cluster_2', \n",
    "                                               value_name='score')\n",
    "# Step 2: Rename columns for clarity\n",
    "mapping_long = mapping_long.rename(columns={'index': 'cluster_1'})\n",
    "# Step 3: Identify species based on prefix\n",
    "def get_species(label):\n",
    "    if label.startswith(\"mm_\"):\n",
    "        return \"mouse\"\n",
    "    elif label.startswith(\"hs_\"):\n",
    "        return \"human\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "mapping_long['species_1'] = mapping_long['cluster_1'].apply(get_species)\n",
    "mapping_long['species_2'] = mapping_long['cluster_2'].apply(get_species)\n",
    "# Step 4: Filter for correct pairings only (mouse vs human)\n",
    "mapping_long = mapping_long[\n",
    "    ((mapping_long['species_1'] == 'mouse') & (mapping_long['species_2'] == 'human')) |\n",
    "    ((mapping_long['species_1'] == 'human') & (mapping_long['species_2'] == 'mouse'))\n",
    "].copy()\n",
    "# Step 5: Standardize columns: always make mouse → human direction\n",
    "# If cluster_1 is mouse and cluster_2 is human, keep as is\n",
    "# If it's reversed, swap them\n",
    "def reorder_clusters(row):\n",
    "    if row['species_1'] == 'mouse':\n",
    "        return pd.Series({'mouse_cluster': row['cluster_1'], 'human_cluster': row['cluster_2'], 'score': row['score']})\n",
    "    else:\n",
    "        return pd.Series({'mouse_cluster': row['cluster_2'], 'human_cluster': row['cluster_1'], 'score': row['score']})\n",
    "\n",
    "mapping_clean = mapping_long.apply(reorder_clusters, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load human cluster annotations\n",
    "human_labels = pd.read_csv(\"1_final_celltype.tsv\", sep=\"\\t\")\n",
    "human_labels = human_labels.rename(columns={'Cluster ID': 'human_cluster_id', 'cell_ontology_term': 'human_label'})\n",
    "# 2. Clean human cluster column: convert 'hs_32' → 32\n",
    "mapping_clean['human_cluster_id'] = mapping_clean['human_cluster'].str.extract(r'hs_(\\d+)').astype(int)\n",
    "# 3. Find top-scoring mouse cluster for each human cluster\n",
    "top_mouse_per_human = (\n",
    "    mapping_clean.sort_values('score', ascending=False)\n",
    "    .groupby('human_cluster_id')\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "# 4. Join with human label\n",
    "top_mouse_per_human = top_mouse_per_human.merge(human_labels, on='human_cluster_id', how='left')\n",
    "# 5. Clean mouse label (remove 'mm_' prefix for comparison)\n",
    "top_mouse_per_human['mouse_label'] = top_mouse_per_human['mouse_cluster'].str.replace('mm_', '', regex=False)\n",
    "# 6. Evaluate agreement (exact match only)\n",
    "top_mouse_per_human['label_match'] = (\n",
    "    top_mouse_per_human['mouse_label'].str.lower() == top_mouse_per_human['human_label'].str.lower()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate accuracy\n",
    "exact match rate = 37% - surprisingly high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_rate = top_mouse_per_human['label_match'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breakdown mismatches (all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mismatches\n",
    "mismatches = top_mouse_per_human[~top_mouse_per_human['label_match']]\n",
    "# Show most common mismatched pairs\n",
    "mismatch_counts = (\n",
    "    mismatches.groupby(['human_label', 'mouse_label'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "mismatch_counts.to_csv(\"outputs/mismatch_counts_all.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breakdown mismatches again but removing broad human labels\n",
    "broad is where cell_ontology_term = neuron or cell - to look at these separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_labels = ['CL:0000540', 'CL:0000000']\n",
    "specific_human_clusters = top_mouse_per_human[~top_mouse_per_human['cell_ontology_term_id'].isin(broad_labels)]\n",
    "mismatches_specific = specific_human_clusters[~specific_human_clusters['label_match']]\n",
    "specific_mismatch_counts = (\n",
    "    mismatches_specific.groupby(['human_label', 'mouse_label'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_rate_specific = specific_human_clusters['label_match'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy after removing broad human terms\n",
    "accuracy is now 49%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look into these mismatches and score them as complete mismatch or fuzzy mismatch - manual, see tsv file\n",
    "could break these into close match, not similar but not mutually exclusive, and complete discordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_mismatch_counts.to_csv(\"outputs/mismatch_counts_specific.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at additional insight given by mouse data for Miscellaneous and Splatter subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_labels = ['CL:0000540', 'CL:0000000']\n",
    "broad_human_clusters = top_mouse_per_human[top_mouse_per_human['cell_ontology_term_id'].isin(broad_labels)]\n",
    "mismatches_broad = broad_human_clusters[~broad_human_clusters['label_match']]\n",
    "broad_mismatch_counts = (\n",
    "    mismatches_broad.groupby(['human_label', 'mouse_label'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "broad_mismatch_counts.to_csv(\"outputs/mismatch_counts_broad.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at Neurotransmitter auto_annotation to confirm some mouse predictions\n",
    "maybe david has some insight on what to do for other predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maybe implement a score threshold and redo some of the previous breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
